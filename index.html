<!DOCTYPE html>
<html>
<head>
	<title>Harsha Koduri</title>
	<meta charset="UTF-8">
	<meta name="google-site-verification" content="LQ0zxBssgeIreYCy7hynWggUI4_02u9W7PhZ1yDIQPo" />
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Josefin+Sans:400,400i,600,600i,700" rel="stylesheet">

	<!-- Stylesheets -->
	<link rel="stylesheet" href="css/bootstrap.min.css"/>
	<link rel="stylesheet" href="css/font-awesome.min.css"/>
	<link rel="stylesheet" href="css/magnific-popup.css"/>
	<link rel="stylesheet" href="css/custom.css"/>
</head>
<body>

	<nav class="navbar navbar-expand-sm navbar-dark" style="background-color: #1687a7;">
	  <ul class="navbar-nav">
	    <li class="nav-item active">
	      <a id="home" class="nav-link" href="#">Home</a>
	    </li>
		<li class="nav-item">
			<a id="publications" class="nav-link" href="#">Publications</a>
		  </li>
	    <li class="nav-item">
	      <a id="projects" class="nav-link" href="#">Projects</a>
	    </li>
		<li class="nav-item">
			<a id="internships" class="nav-link" href="#">Internships</a>
		  </li>
		<li class="nav-item">
			<a id="certification" class="nav-link" href="#">Certifications</a>
		  </li>
	    <li class="nav-item">
	      <a href="docs/Resume_phd.pdf" class="nav-link">Resume</a>
	    </li>
	  </ul>
	</nav>
	<div class="container-fluid" >
		<div class="row">
			<div class="col-lg-12">

			</div>
		</div>
		<div class="row" style="text-align: center;">
			<!-- <div class="col-lg-2"></div> -->
			<div class="col-lg-4" >
				<!-- <svg style="width:100%;" height="250">
				  <defs>
				    <pattern id="image" x="0%" y="0%" height="100%" width="100%"
				             viewBox="0 0 512 512">
				      <image x="0%" y="0%" width="512" height="512" xlink:href="img/dp1.jpg"></image>
				    </pattern>
				  </defs>
				   <rect x="100" y="20" height="250" width='250' stroke="grey" stroke-width="3" fill="url(#image)" /> -->
				<!-- </svg> -->
				<div style="text-align: center;">
					<image x="0%" y="0%" width="250" height="250" src="img/dp.jpeg"></image>
					<h4>Harsha Koduri</h4>
					<p>harsha.koduri123@gmail.com</p>

				</div>

				
		 <div style="display: flex; align-items: center; gap: 20px; flex-wrap: wrap; font-family: Arial, sans-serif; font-size: 16px;">
			<!-- Location -->
			<div>
			  üìç NYC, NY
			</div>
		  
			<!-- GitHub -->
			<div>
			  <a href="https://github.com/HarshaKoduri123" target="_blank" style="text-decoration: none; color: inherit;">
				<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="GitHub" width="24" style="vertical-align: middle;">
				GitHub
			  </a>
			</div>
		  
			<!-- Google Scholar -->
			<div>
			  <a href="https://scholar.google.com/citations?hl=en&authuser=2&user=gnr6_hUAAAAJ" target="_blank" style="text-decoration: none; color: inherit;">
				<img src="https://upload.wikimedia.org/wikipedia/commons/c/c7/Google_Scholar_logo.svg" alt="Google Scholar" width="24" style="vertical-align: middle;">
				Google Scholar
			  </a>
			</div>
		</div>

			</div>
			<div class="col-lg-6" style="margin-top: 50px;" >
				<div id="home_div" class="row section" style="margin-left: 5px;margin-right: 5px;">
					<p>Hi, I‚Äôm Harsha Koduri. I‚Äôm a Research Assistant at Yeshiva University in New York, My advisor is Prof. Ming Ma. </p>
					<!-- My recent projects include- Visual causal analysis for transparent decision-making, Collaborative sense-making through causal inference, and Interactive tool for balancing visual biases (gender bias, skin-tone bias etc.) in live telecasts.</p> -->

					<p>I hold a Master‚Äôs degree in Artificial Intelligence from Yeshiva University, a MicroMasters in Statistics and Data Science from MIT, and a Bachelor's in Computer Science from BML Munjal University in India.</p>
					<div>
						<h4> Recent News! </h4>
						<ul>
							<li>February, 2025: Our paper ‚ÄúLLM-TAMIS: Large Language Model based Text-Augmented Medical Image Segmentation‚Äù was submitted to MICCAI 2025.</li>
							<li>February, 2025: Presented a poster titled ‚ÄúOTID: Optimal Transport-Based Low-Dose CT Image Denoising‚Äù at SPIE Medical Imaging 2025 in San Diego, California.</li>
							<li>October, 2024: Our Paper ‚ÄúOTID: Optimal Transport-Based Low-Dose CT Image Denoising‚Äù was accepted at SPIE Medical Imaging 2025.</li>
							<li>August, 2024: Our paper ‚ÄúDiabetic and Hypertensive Retinopathy Classification from Retinal Images Using Dual Vision Transformer‚Äù was accepted at International Conference on Digital Data Processing (DDP 2024).</li>
							<li>July, 2024: Joined as a Research Assistant at Yeshiva University, New York, working under the guidance of Prof. Ma Ming.</li>
							<li>December, 2023: Our paper ‚ÄúAutomatic Classification of Diabetic and Hypertension Fundus Camera Retinal Images Using Deep Learning‚Äù was accepted at the International Conference on Signal, Machines, Automation, and Algorithm.</li>
						</ul>

					</div>

				</div>
				<div id="publications_div" class="row section" style="margin-left:5px;margin-right: 5px;">
					<h4>Publications</h4>

					<ul>
						<li>

							<b>Koduri Harsha</b>, Ma Ming. "OTID: Optimal Transport-Based Low-Dose CT Image Denoising." <b>SPIE Medical Imaging, 2025,</b> pp. 13406-99 <a href="https://doi.org/10.1117/12.3047378">. Paper</a>.

						</li><br>

						<li>

							<b>Koduri Harsha</b>, Ma Ming. "Diabetic and Hypertensive Retinopathy Classification from Retinal Images Using Dual Vision Transformer." International Conference on <b>Digital Data Processing (DDP 2024)</b>, 2024. <a href="https://doi.ieeecomputersociety.org/10.1109/DDP64453.2024.00034">. Paper</a>
						</li><br>
					
						<li>
							Ajay Vamsi Jalluri, Harsha Vardhan Garine, <b>Harsha Vardhan Koduri</b>,  Kiran Khatter, Soharab Hossain Shaikh, Devanjali Relan. "Automatic Classification of Diabetic and Hypertension Fundus Camera Retinal Images Using Deep Learning." International Conference on <b>Signal, Machines, Automation, and Algorithm</b> <a href="https://doi.org/10.1007/978-981-97-6352-8_11"> Paper</a>

						</li><br>
					

		            </ul>
				</div>

				<div id="projects_div" class="row section" style="margin-left: 5px;margin-right: 5px;">

					<div>
						<h4>Projects</h4>
						<ul>

							<li>
								<p><strong>LLM-TAMIS</strong> | Pytorch</p>
								<ul>
								  <li>Developed a <strong>multimodal segmentation model</strong> that processes both medical images and clinical text, enhancing segmentation accuracy by integrating contextual information from radiology reports.</li>
								  <li>Implemented <strong>LLaMa 3.2 a Large Language Model (LLM)</strong> and <strong>Vision Transformer (ViT)</strong> to extract meaningful text embeddings and align them with image features, improving feature representation.</li>
								  <li>Designed a <strong>CNN-based U-Net architecture</strong> for medical image segmentation and introduced a novel <strong>Spatial Channel Driven Module (SCDM)</strong> to refine spatial and channel feature extraction.</li>
								  <li><strong>Achieved state-of-the-art results</strong> on the <strong>MosMedData+</strong> and <strong>QaTa-COV19</strong> datasets, outperforming existing methods in <strong>Dice score</strong> and <strong>mIoU</strong> evaluation metrics.</li>
								  <li>This research was submitted to the <strong>MICCAI 2025</strong> conference, <strong>one of the top conferences for medical imaging using AI</strong>.</li>
								</ul>

 					    </li><br>
							<li>
								<p><strong>Voice Cloning</strong> | Pytorch</p>
								<ul>
								  <li>Developed a <strong>deep learning-based Text-to-Speech (TTS) system</strong>, combining a sequence-to-sequence model for mel spectrogram generation with a WaveNet vocoder for waveform synthesis.</li>
								  <li>Implemented a <strong>CNN-based encoder</strong> with character embeddings, followed by a <strong>bi-directional LSTM</strong> and <strong>location-sensitive attention</strong> to align input text with spectrogram frames dynamically.</li>
								  <li>Designed an <strong>autoregressive LSTM decoder</strong> to predict mel spectrograms, incorporating a <strong>convolutional post-net</strong> to refine spectrogram outputs for improved synthesis quality.</li>
								  <li>Trained a modified <strong>WaveNet vocoder</strong> with <strong>dilated CNNs</strong>, conditioned on mel spectrograms, and utilized <strong>Mixture of Logistics (MoL)</strong> loss for realistic speech waveform generation.</li>
								  <li><strong>Achieved state-of-the-art speech synthesis</strong> on dataset <strong>LibriSpeech</strong> and <strong>custom recordings</strong> (including my professor‚Äôs voice).</li>
								</ul>

 					    </li><br>
							<li>
								<p><strong>Autonomous Driving</strong> | Python, Carla</p>
								<ul>
								  <li>Developed a program for an autonomous vehicle in the <strong>CARLA simulator</strong>.</li>
								  <li>The vehicle‚Äôs Longitudinal and Lateral directions were controlled by a <strong>PID</strong> and <strong>Stanley controller</strong>.</li>
								  <li>Implemented <strong>Uncensored Kalman filters</strong> for state estimation by taking data from the sensors Lidar Radar and Camera.</li>
								  <li>Developed a <strong>3D perception</strong> pipeline using camera coordinate frames with downward y-axis for height estimation, including<strong> SVD-based plane estimation</strong>,<strong> Hough transform-based</strong> lane boundary detection with slope filtering, and <strong> object detection filtering</strong> via normalized pixel counts.</li>
								  <li>Implemented <strong>behavioral planning logic</strong>, <strong>static collision checking</strong>, <strong> path selection</strong>, and <strong>velocity profile generation </strong> for path planning.</li>
								</ul>

 					    </li><br>


							 
						</ul>
					</div>

				</div>
				<div id="internships_div" class="row section" style="margin-left:5px;margin-right: 5px;">
					<h4>Internships</h4>

					<ul>
						<li>
						  <strong>AI Research Assistant</strong> [Aug 2024 - Current]<br>
						  <em>Yeshiva University, New York</em>
						  <ul>
							<li><strong>Conducted research in AI</strong>, focusing on Machine Learning, Deep Learning, and Large Language Models (LLMs) techniques under <strong>Professor Ming Ma</strong>.</li>
							<li>Developed <strong>LLM-TAMIS</strong>, a Large Language Model-based Text-Augmented Medical Image Segmentation framework integrating clinical text and images, improving segmentation accuracy; submitted to <strong>MICCAI 2025</strong>.</li>
							<li>Proposed <strong>OTID (Optimal Transport-based Image Denoising)</strong>, using Wasserstein GAN with attention mechanisms for <strong>low-dose CT image denoising</strong>, achieving state-of-the-art performance; accepted at <strong>SPIE Medical Imaging 2024</strong>.</li>
							<li>Designed a <strong>Dual Vision Transformer model</strong> for diabetic and hypertensive retinopathy classification, enhancing feature extraction and classification accuracy; accepted at <strong>Digital Data Processing (DDP) 2024</strong>.</li>
						  </ul>
						</li><br>
					  
						<li>
						  <strong>Data Science Intern</strong> [Jan 2022 - Jun 2022]<br>
						  <em>Sabudh Foundations, Punjab</em>
						  <ul>
							<li>Developed a <strong>deep learning model to improve Single Image Super-Resolution (SISR)</strong> by generating high-resolution images from low-resolution inputs.</li>
							<li>Proposed a <strong>GAN-based approach</strong> with a generator using residual blocks, sub-pixel convolution for upscaling, and batch normalization, along with a <strong>VGG-style discriminator</strong> with LeakyReLU activation, while designing a perceptual loss that combines VGG-based feature reconstruction to preserve details and adversarial loss for realistic textures.</li>
							<li>The model outperformed conventional super-resolution techniques, producing sharper, more realistic images with improved texture details and perceptual quality.</li>
						  </ul>
						</li><br>
					  
						<li>
						  <strong>Machine Learning Intern</strong> [May 2020 - July 2020]<br>
						  <em>Cigniti Technologies, Hyderabad</em>
						  <ul>
							<li>Worked on a <strong>Sentiment Analysis</strong> project. Tasked with analyzing customer reviews and classifying them using Deep Learning Models.</li>
							<li>Built <strong>Positive-Negative and Service-Product classifiers</strong> using datasets provided by the company. A <strong>Word2Vec</strong> pre-trained model was used for text embeddings, which were fed into an <strong>LSTM model</strong> and trained for 1000 epochs. The final model was deployed in the <strong>AWS cloud</strong>.</li>
						  </ul>
						</li>
					  </ul>

				</div>

			

				<div id="certification_div" class="row section" style="margin-left:5px;margin-right: 5px;">
					<h4>CERTIFICATIONS</h4>

					<ul>
					<li>
						<strong>Reinforcement Learning</strong> <a href="https://coursera.org/share/b7a35e7c927e588cfb78d46adf02487d"> Certificate</a><br>
						University of Alberta, Alberta Machine Intelligence Institute
					</li>
					
					<li>
						<strong>Self-Driving Cars</strong> <a href="https://coursera.org/share/e4b359a7ad9f3b3ae56ae974d322c0ac"> Certificate</a><br>
						University of Toronto
					</li>
					
					<li>
						<strong>Modern Robotics: Mechanics, Planning, and Control</strong><a href="https://coursera.org/share/29b1b34077a536e0f1fa1a63ee3b7158"> Certificate</a><br>
						Northwestern University
					</li>
					
					<li>
						<strong>Deep Learning</strong><a href="https://coursera.org/share/52570bb40dff06422e5e408a815f2031"> Certificate</a><br>
						DeepLearning.AI
					</li>

					<li>
						<strong>Mathematics for Machine Learning</strong><a href="https://coursera.org/share/5b9af5c0f9cac53b3f7da0b22a5b554a"> Certificate</a><br>
						Imperial College London
					</li>
					</ul>

				</div>

			</div>
			
		</div>
	</div>


	<script src="js/jquery-2.1.4.min.js"></script>
	<script src="js/bootstrap.min.js"></script>
	<script type="text/javascript" src="js/index.js"></script>

</body>
</html>
